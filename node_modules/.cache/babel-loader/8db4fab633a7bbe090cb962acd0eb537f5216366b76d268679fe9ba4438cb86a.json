{"ast":null,"code":"// src/services/api.js\nimport axios from 'axios';\n\n// Mock API service - replace with actual LLM API integration\nexport const generateRecipeResponse = async (prompt, context) => {\n  // Simulate API call delay\n  await new Promise(resolve => setTimeout(resolve, 2000));\n\n  // Mock responses based on context and prompt\n  const mockResponses = [\"Based on your recipes, I can suggest some variations...\", \"I see you have several recipes uploaded. Would you like me to help you organize them?\", \"Looking at your ingredients, here's what you could make...\", \"I can help you modify any recipe to be healthier or accommodate dietary restrictions.\", \"Based on your uploaded files, I can analyze your cooking patterns and suggest improvements.\"];\n\n  // Simple keyword-based response generation\n  if (prompt.toLowerCase().includes('healthy')) {\n    return \"For a healthier version, try reducing oil by 25%, using whole wheat flour instead of white, and adding more vegetables to boost nutrition.\";\n  }\n  if (prompt.toLowerCase().includes('quick') || prompt.toLowerCase().includes('fast')) {\n    return \"Here's a quick recipe idea: 15-minute pasta with garlic, olive oil, and fresh herbs. Perfect for busy weeknights!\";\n  }\n  if (prompt.toLowerCase().includes('vegetarian')) {\n    return \"For a vegetarian option, you can substitute meat with mushrooms, lentils, or tofu. I can help you modify any of your recipes.\";\n  }\n  return mockResponses[Math.floor(Math.random() * mockResponses.length)];\n};\n\n// Example of actual API integration (commented out)\n/*\r\nexport const generateRecipeResponseReal = async (prompt, context) => {\r\n  const response = await axios.post('https://your-llm-api.com/recipes', {\r\n    prompt,\r\n    context: {\r\n      recipeCount: context.recipes.length,\r\n      fileNames: context.files,\r\n      sampleRecipes: context.recipes.slice(0, 3) // Send first 3 recipes as context\r\n    }\r\n  });\r\n  return response.data.message;\r\n};\r\n*/","map":{"version":3,"names":["axios","generateRecipeResponse","prompt","context","Promise","resolve","setTimeout","mockResponses","toLowerCase","includes","Math","floor","random","length"],"sources":["C:/Users/A/Desktop/oid model/recipe-llm-app/src/services/api.js"],"sourcesContent":["// src/services/api.js\r\nimport axios from 'axios';\r\n\r\n// Mock API service - replace with actual LLM API integration\r\nexport const generateRecipeResponse = async (prompt, context) => {\r\n  // Simulate API call delay\r\n  await new Promise(resolve => setTimeout(resolve, 2000));\r\n\r\n  // Mock responses based on context and prompt\r\n  const mockResponses = [\r\n    \"Based on your recipes, I can suggest some variations...\",\r\n    \"I see you have several recipes uploaded. Would you like me to help you organize them?\",\r\n    \"Looking at your ingredients, here's what you could make...\",\r\n    \"I can help you modify any recipe to be healthier or accommodate dietary restrictions.\",\r\n    \"Based on your uploaded files, I can analyze your cooking patterns and suggest improvements.\"\r\n  ];\r\n\r\n  // Simple keyword-based response generation\r\n  if (prompt.toLowerCase().includes('healthy')) {\r\n    return \"For a healthier version, try reducing oil by 25%, using whole wheat flour instead of white, and adding more vegetables to boost nutrition.\";\r\n  }\r\n\r\n  if (prompt.toLowerCase().includes('quick') || prompt.toLowerCase().includes('fast')) {\r\n    return \"Here's a quick recipe idea: 15-minute pasta with garlic, olive oil, and fresh herbs. Perfect for busy weeknights!\";\r\n  }\r\n\r\n  if (prompt.toLowerCase().includes('vegetarian')) {\r\n    return \"For a vegetarian option, you can substitute meat with mushrooms, lentils, or tofu. I can help you modify any of your recipes.\";\r\n  }\r\n\r\n  return mockResponses[Math.floor(Math.random() * mockResponses.length)];\r\n};\r\n\r\n// Example of actual API integration (commented out)\r\n/*\r\nexport const generateRecipeResponseReal = async (prompt, context) => {\r\n  const response = await axios.post('https://your-llm-api.com/recipes', {\r\n    prompt,\r\n    context: {\r\n      recipeCount: context.recipes.length,\r\n      fileNames: context.files,\r\n      sampleRecipes: context.recipes.slice(0, 3) // Send first 3 recipes as context\r\n    }\r\n  });\r\n  return response.data.message;\r\n};\r\n*/"],"mappings":"AAAA;AACA,OAAOA,KAAK,MAAM,OAAO;;AAEzB;AACA,OAAO,MAAMC,sBAAsB,GAAG,MAAAA,CAAOC,MAAM,EAAEC,OAAO,KAAK;EAC/D;EACA,MAAM,IAAIC,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAE,IAAI,CAAC,CAAC;;EAEvD;EACA,MAAME,aAAa,GAAG,CACpB,yDAAyD,EACzD,uFAAuF,EACvF,4DAA4D,EAC5D,uFAAuF,EACvF,6FAA6F,CAC9F;;EAED;EACA,IAAIL,MAAM,CAACM,WAAW,CAAC,CAAC,CAACC,QAAQ,CAAC,SAAS,CAAC,EAAE;IAC5C,OAAO,4IAA4I;EACrJ;EAEA,IAAIP,MAAM,CAACM,WAAW,CAAC,CAAC,CAACC,QAAQ,CAAC,OAAO,CAAC,IAAIP,MAAM,CAACM,WAAW,CAAC,CAAC,CAACC,QAAQ,CAAC,MAAM,CAAC,EAAE;IACnF,OAAO,mHAAmH;EAC5H;EAEA,IAAIP,MAAM,CAACM,WAAW,CAAC,CAAC,CAACC,QAAQ,CAAC,YAAY,CAAC,EAAE;IAC/C,OAAO,+HAA+H;EACxI;EAEA,OAAOF,aAAa,CAACG,IAAI,CAACC,KAAK,CAACD,IAAI,CAACE,MAAM,CAAC,CAAC,GAAGL,aAAa,CAACM,MAAM,CAAC,CAAC;AACxE,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}